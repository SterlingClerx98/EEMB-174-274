---
title: 'Day 9: Post-treatment bias'
author: "Stephen R. Proulx"
date: "1/10/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rethinking)
source("../Resources/helper.R")

```

# Today's objectives:  

* Indexing Categorical Variables: Similar method to linear regression but without a line      
* Post-treatment bias: Bad for hypothesis testing, fine for fitting

 


## Categorical variables
Linear regression involves assuming that a model for how a predictor affects the likelihood function. It is a specific model, where there is a linear function relating the predictor to the outcome. We often have predictors that we don't have a model for, and we want to estimate each of their effects assuming that each value of the predictor has it's own independent effect. This is the case when we have "categorical" predictors.


NOTE: There can be more than one observation with the same categorical index.  
```{r}
 

covid_cases <- tibble(name=c("Santa Barbara" , "Goleta", "Santa Maria"), loc=c(1,2,3), pop=c(92100,31100,107000) , cases=c(5276,1485,9980))


```

```{r}
m.covid <- quap( alist(
  cases ~ dbinom(pop,mu[loc]),
  mu[loc] ~ dunif(0,1)
) , data=covid_cases 
)



precis(m.covid,depth = 2)
```


```{r}
samples.covid <- extract.samples(m.covid) %>% as_tibble()
bayesplot::mcmc_intervals(samples.covid)
```
 
### Exercise: Multiple observations within a category
Construct a new dataset that has observations of covid case numbers at multiple locations within Santa Barbara County and within Ventura County. Data for Ventura are at https://www.venturacountyrecovers.org/. Use the data I gave you Santa Barbara county, adding a column to code for county index. Add data for Ojai, Santa Paula, and Fillmore (you can find the population sizes of these municipalities) and code them as from Ventura County. Construct a model that estimates the rate of covid cases by county.

## Post-treatment bias
In the book, McElreath develops a simulation model for a dataset where plants are treated with a fungicide, and presence of fungus has a causal effect on growth. Here's the model: 
```{r}
set.seed(71)
# number of plants
N <- 100

# simulate initial heights
h0 <- rnorm(N,10,2)

# assign treatments and simulate fungus and growth
treatment <- rep( 0:1 , each=N/2 )
fungus <- rbinom( N , size=1 , prob=0.5 - treatment*0.4 )
h1 <- h0 + rnorm(N, 5 - 3*fungus)

# compose a clean data frame
sim_plant_data <- data.frame( h0=h0 , h1=h1 , treatment=treatment , fungus=fungus )
precis(sim_plant_data)


```


### Fitting models with treatment and post-treatment effects
Construct two quap models to explore the effect of treatment on plant height. One model will include the effect of the fungicide treatment, the other will additionally include the effect of presence of fungus on the plant post-treatment. 

We want to control for growth, but here we have a very specific model. Plants grow by multiplying their original height by a growth factor. Both models should include the effect of original plant height, h0.

model with treatment
```{r}
m6.7 <- quap(
    alist(
        h1 ~ dnorm( mu , sigma ),
        mu <- h0 * p,
        p <- a + bt*treatment + bf*fungus,
        a ~ dlnorm( 0 , 0.2 ) ,
        bt ~ dnorm( 0 , 0.5 ),
        bf ~ dnorm( 0 , 0.5 ),
        sigma ~ dexp( 1 )
    ), data=sim_plant_data )
precis(m6.7)
```


```{r} 
m6.8 <- quap(
    alist(
        h1 ~ dnorm( mu , sigma ),
        mu <- h0 * p,
        p <- a + bt*treatment,
        a ~ dlnorm( 0 , 0.2 ),
        bt ~ dnorm( 0 , 0.5 ),
        sigma ~ dexp( 1 )
    ), data=sim_plant_data )
precis(m6.8)


```

### "Residuals" of the model fits
We will do a different kind of posterior plot than we have so far done. We will calculate the difference between the model expectation (i.e. mu) and the actual plant height, h1. We do this in almost the same way as we did for our other posterior simulations, but we add a column, using mutate, that calculates the squared difference between h1 and the mean of mu. Soemthing like: `mutate(res.h1 = (h1-mean.mu)^2 )`

Create this residual for both of your models and plot them on a single plot, giving each model a different color.

```{r}

samples.m6.7 <- link_df(m6.7,sim_plant_data)

summarised.samples.m6.7 <- group_by(samples.m6.7,index) %>%
  summarise(mean.mu=mean(mu),
            lower.mu=quantile(mu,0.1),
            upper.mu=quantile(mu,0.9))%>%
  ungroup() %>%
  left_join(rowid_to_column(sim_plant_data,"index")) %>%
  mutate(res.h1 = (h1-mean.mu)^2 )

```

```{r}

samples.m6.8 <- link_df(m6.8,sim_plant_data)

summarised.samples.m6.8 <- group_by(samples.m6.8,index) %>%
  summarise(mean.mu=mean(mu),
            lower.mu=quantile(mu,0.1),
            upper.mu=quantile(mu,0.9))%>%
  ungroup() %>%
 left_join(rowid_to_column(sim_plant_data,"index")) %>%
  mutate(res.h1 = (h1-mean.mu)^2 )

ggplot(summarised.samples.m6.8, aes(x=index,y=res.h1))+
  geom_point(color="red")  +
  geom_point(data=summarised.samples.m6.7, color="green")
  
```
We can observe that the green dots tend to be closer to 0 than the red dots. 