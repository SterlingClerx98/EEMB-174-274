---
title: "Feb 24, MCMC regularization"
author: "Stephen R. Proulx"
date: "2/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rethinking)
source("../Resources/helper.R")
```

# Today's objectives:  
* Learn the `ulam` syntax (with working computer environments this time)
* Learn some basic ways to diagnose and regularize your Markov chains
* Understand how GLMs are built
* Learn how to perform a simple GLM using the binomial and the Poisson likelihood function 


## Some notes on `ulam` output
`ulam` includes multiple objects in the output it produces. You can access the output from stan with `@stanfit`. This stanfit object includes the samples from the posterior, and you can use any tool that works with stanfit objects on it. There are many packages that work with stanfit objects, we will use some from `bayesplot`.

Example:
```{r , eval=FALSE}
m.ulam.example <- ulam( ... )


stanfit.ulam.example <- m.ulam.example@stanfit
```

You already have a lot of skills for working with samples of parameters from the posterior. You can retreive these from the stanfit object or from the ulam object. These two statements produce the same dataframe. Note that I am explicitly stating which package the extract function comes from to avoid ambiguity.
```{r , eval=FALSE}
posterior.samples.stanfit.example <- rstan::extract(stanfit.ulam.example) %>% as_tibble()

posterior.samples.ulam.example <- rethinking::extract.samples(m.ulam.example) %>% as_tibble()
```

## Diagnosing and regularizing stan output
### Extreme example of a very small dataset where regularization helps

Run a model with very little data and a very flat prior
```{r}
## R code 9.22
d <- tibble(y=c(-1,1))

set.seed(11)
m9.2 <- ulam(
    alist(
        y ~ dnorm( mu , sigma ) ,
        mu <- alpha ,
        alpha ~ dnorm( 0 , 1000 ) ,
        sigma ~ dexp( 0.0001 )
    ) , data=d , chains=3 , iter=2000)

## R code 9.23
precis( m9.2 )
```
Let's look more closely at what is going on here.

```{r}
bayesplot::mcmc_pairs(m9.2@stanfit , pars=c("alpha","sigma"  )) 
```


```{r}
traceplot( m9.2 )

trankplot( m9.2 )

```


```{r}
## R code 9.24
set.seed(11)
m9.3 <- ulam(
    alist(
        y ~ dnorm( mu , sigma ) ,
        mu <- alpha ,
        alpha ~ dnorm( 1 , 10 ) ,
        sigma ~ dexp( 1 )
    ) , data=d, chains=3, iter=2000 )

precis( m9.3 )
```

Let's look more closely at what is going on here.
```{r}
bayesplot::mcmc_pairs(m9.3@stanfit , pars=c("alpha","sigma"  ) )
```

```{r}
traceplot( m9.3 )

trankplot( m9.3 )

```


### A model that has non-identifiable parameters
In real world examples, it is easy to write down a model which makes sense but has "non-identifiable" parameters. This just means that multiple combinations of parameters can produce the same or similar patterns of data. These models can careen wildly around parameters space. Some of this can be fixed by using more realistic priors, and also it is often the case that the models are fine at predicting relevant information even when specific parameters are non-identifiable.

Here is an example that makes this very explicit, our two parameters just sum up to determine the mean of a normal likelihood. And here even though the individual parameters are not identifiable, their sum is.

```{r}
## R code 9.25
set.seed(41)
y <- rnorm( 100 , mean=0 , sd=1 )

## R code 9.26
set.seed(384)
m9.4 <- ulam(
    alist(
        y ~ dnorm( mu , sigma ) ,
        mu <- a1 + a2 ,
        a1 ~ dnorm( 0 , 1000 ),
        a2 ~ dnorm( 0 , 1000 ),
        sigma ~ dexp( 1 )
    ) , data=list(y=y) , chains=3,iter=2000 )
```

Look at the summary. It looks not great.
```{r}
precis( m9.4 )
```
```{r}
pairs(m9.4@stanfit, pars=c("a1","a2","sigma"))

traceplot( m9.4 )

trankplot( m9.4 )
```

Even though this model has non-identifiable parameters, it gets the big picture correct. This also highlights one of the great features of model-based statistics, we can use the output of the model in new combinations without much added work. So here we can reconstruct the aggregate parameter $asum=a1+a2$  and use all the same tools we have developed.
```{r}
post=as.data.frame(m9.4@stanfit) %>% mutate(asum=a1+a2) 
mcmcpairs(select(post,asum,sigma) , pars=c("asum","sigma"))
```


Now run the same model but with more restrictive priors and see if our performance metrics improve. 
```{r}
## R code 9.27
m9.5 <- ulam(
    alist(
        y ~ dnorm( mu , sigma ) ,
        mu <- a1 + a2 ,
        a1 ~ dnorm( 0 , 10 ),
        a2 ~ dnorm( 0 , 10 ),
        sigma ~ dexp( 1 )
    ) , data=list(y=y) , chains=3 )
```

The summary looks better, although the individual parameters still vary a lot. Our chains do mix (they have less room from the prior to wiggle in), which we can see from Rhat values near 1. 
```{r}
precis( m9.5 )

```

```{r}
pairs(m9.5@stanfit, pars=c("a1","a2","sigma"))

traceplot( m9.5 )

trankplot( m9.5 )
```

Like before this still gets the total right.
```{r}
post=as.data.frame(m9.5@stanfit) %>% mutate(asum=a1+a2) 
mcmcpairs(select(post,asum,sigma) )
 
```


## GLMs
The basic idea is that we have a likelihood that matches our data type, and then develop an additive model for underlying parameters, and connect the two with a "link" function. The value in this is that the additive model portion is often something that we can have a better idea of which priors to choose. 

Most of the course we've been using normal distributions, and have done this with little specific justification. Our models have been something like

$$
y \sim \mathrm{Normal}(\mu,\sigma) \\
\mu = a + b1 * x1 + b2 * x2 + ... \\
$$
with priors on the parameters.


### Binomial
Now we will be using likelihood functions that fit our data types better. One common scenario that biologists deal with is one where the data are counts of how many individuals had a particular outcome, like survived or reproduced or developed a specific phenotype. We have a strong reason to beleive, a priori, that at least within a replicate batch of individuals, the outcome follows a binomial distribution. So our model might be something like:

$$
y \sim \mathrm{Binomial}(n,p) \\
\mathrm{logit}(p) = a + b1 * x1 + b2 * x2 + ...\\
$$
with priors. Mathematically, this is a fine way of writing, but computationally it is really more like:
$$
y \sim \mathrm{Binomial}(n,p) \\
p = \mathrm{logit}^{-1}(a + b1 * x1 + b2 * x2 + ... )\\
$$

And because of the way the link transformation works, the parameters are now on the $-\infty$ to $\infty$ scale so we can use normal priors. We can also add effects together without worrying about breaking the model by getting $p$ below 0 or above 1. 

Still remember hydrochloroquine? Here is the analysis we did, but logit style. 
```{r}

outcomes = tibble(treatment = c("HC","HC_AZ","None") , 
                  death = c(27,25,18) , 
                  discharge = c(70,88,140) , 
                  HC_indicator = c(1,1,0),
                  AZ_indicator = c(0,1,0)) %>%
  mutate(total=death+discharge)



m.HC.logit <- ulam(alist(
  death ~ dbinom( total , mu ),
  logit(mu) <-  a + HC_indicator * delHC + AZ_indicator * delAZ,
  a ~ dnorm(0,1),
  delHC ~ dnorm(0,0.1),
  delAZ ~ dnorm(0,0.05)),
  data=outcomes,
  chains=4,cores=4,iter=2000
)

precis(m.HC.logit )

```
These are already sort of interpretable: $a$ is negative, and the inverse logit of -1.5 is ~0.2. The two del paramaters are not negative, suggesting that they increase death rate.  

We can get back to our natural scale, though, and see how things look there.
```{r}
post=extract(m.HC.logit@stanfit)%>%as_tibble()%>%
  mutate(mu_none=inv_logit(a),
         mu_HC=inv_logit(a+delHC),
         mu_HC_AZ=inv_logit(a+delHC+delAZ))

bayesplot::mcmc_intervals(select(post,mu_none,mu_HC,mu_HC_AZ,delHC))


```



### Poisson

Another common scenario is count data where the upper limit might be quite large. Number of offsping produced, for example. In this case, a fine a priori model is the Poisson distribution. Our model might be something like:

$$
y \sim \mathrm{Poisson}(\lambda) \\
\mathrm{log}(\lambda) = a + b1 * x1 + b2 * x2 + ...\\
$$
with priors. Again we could put the inverse function on the other side and get
$$
y \sim \mathrm{Poisson}(\lambda) \\
\lambda = \mathrm{log}^{-1}(a + b1 * x1 + b2 * x2 + ... )\\
$$
Of course, here the inverse of log is the exponential function. And again, the scale of our parameter has now been shifted onto $-\infty$ to $\infty$.


LA covid cases, in the fall surge.
```{r}
load("LACases.rds")

```

Turns out `stan` can't handle column names with `.` in them. Do not ask how many minutes it took for me to remember this...
```{r}
LACases <- rename(LACases, newcases=new.cases)  
```


```{r}
 ggplot(data=LACases,aes(x=day,y=newcases))+geom_point()

```

We can model this using a Poisson, since the number of people in LA is much much larger than the number infected per day. Our additive model portion will be to assume that day has an affect on the parameter (of course it isn't really day, it is number of infected people walking around, but the statistical association is still there).
```{r}
m.LACases.q <- quap(
  alist(
    newcases ~ dpois(lambda) ,
    log(lambda) <- a +  b  * day ,
    a ~ dnorm(0,10) ,
    b  ~ dnorm(0,2)
  ) , data = LACases)

precis(m.LACases.q) 

```


```{r}
m.LACases.u <- ulam(
  alist(
    newcases ~ dpois(lambda) ,
    log(lambda) <- a +  b  * day ,
    a ~ dnorm(0,10) ,
    b  ~ dnorm(0,2)
  ) , data = LACases , cores=4, chains=4, iter=3000)
 
precis(m.LACases.u) 


```

How did our model do in terms of capturing the pattern? 
```{r}
sim.LACases <- rethinking::sim(m.LACases.u,data=LACases) %>% as_tibble()%>%
 gather( "index","cases",1:49) %>%
  separate(index,c("V","day"),sep=1) %>%
  mutate(day=as.numeric(day))

summary.sim.LACases <- group_by(sim.LACases,day) %>%
  summarise(mean.cases = mean(cases),
    lower.cases = quantile(cases,0.1),
    upper.cases = quantile(cases,0.9)) %>%
  ungroup()

ggplot(summary.sim.LACases, aes(x=day,y=mean.cases))+
  geom_point()+
  geom_errorbar( aes(ymin=lower.cases,ymax=upper.cases))+
  geom_point(data=LACases, aes(x=day,y=newcases), color="red")
  
```


